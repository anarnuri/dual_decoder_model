{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from model import Transformer\n",
    "from dataset import TransformerDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import shutil\n",
    "from sim import simulate_mechanism\n",
    "from utils import preprocess_curves\n",
    "import random \n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_ddp_model(model, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Extract the state dict if it's stored under \"model_state_dict\"\n",
    "    if \"model_state_dict\" in checkpoint:\n",
    "        state_dict = checkpoint[\"model_state_dict\"]\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    # Remove DDP wrapper key, if present\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        new_key = k.replace(\"module.\", \"\") if k.startswith(\"module.\") else k\n",
    "        new_state_dict[new_key] = v\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "model = Transformer(output_size=2,\n",
    "                    tgt_seq_len=10,\n",
    "                    d_model=1024,\n",
    "                    h=32,\n",
    "                    N=6)\n",
    "\n",
    "model = load_ddp_model(model, \"weights/clip/d1024_h32_bs512_lr0.0001_best.pth\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TransformerDataset(\n",
    "        data_dir='/home/anurizada/Documents/nobari_10_transformer',\n",
    "    )\n",
    "data_loader = DataLoader(dataset, shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_conditional(model, source, adj_type, max_len, eos_token=torch.tensor([1.0, 1.0])):\n",
    "    model, source = model.to(device), source.to(device)\n",
    "    adj_type = adj_type.to(device)\n",
    "\n",
    "    # Encode the source once with conditioning on mech_type\n",
    "    encoder_output, curve_emb, adj_emb = model.encode(source, adj_type)\n",
    "\n",
    "    # Initial inputs for the decoders\n",
    "    decoder_input_first = torch.ones(1, 1, 2).to(device) * -2.0 # Start token for decoder 1\n",
    "    decoder_input_second = torch.ones(1, 1, 2).to(device) * -2.0 # Start token for decoder 2\n",
    "\n",
    "    # Decoded outputs for both decoders\n",
    "    decoded_first = []\n",
    "    decoded_second = []\n",
    "\n",
    "    # First decoding loop\n",
    "    while decoder_input_first.size(1) < max_len // 2:\n",
    "        # Build causal mask for decoder 1\n",
    "        decoder_mask_first = causal_mask(decoder_input_first.size(1)).type_as(decoder_input_first).to(device)\n",
    "\n",
    "        # Decode using the first decoder with its specific positional encoding\n",
    "        decoder_output_first = model.decode(\n",
    "            model.decoder_first,\n",
    "            encoder_output,\n",
    "            None,\n",
    "            decoder_input_first,\n",
    "            decoder_mask_first,\n",
    "            model.decoder_positional_encoding_first  # Pass the first positional encoding\n",
    "        )\n",
    "        proj_output_first = model.projection_first(model.projection_norm_first(decoder_output_first))\n",
    "\n",
    "        # Get the next predicted token\n",
    "        next_token_first = proj_output_first[:, -1].unsqueeze(0)\n",
    "\n",
    "        # Append to the decoded sequence\n",
    "        decoded_first.append(next_token_first.squeeze(0).detach().cpu())\n",
    "\n",
    "        # Check for the EOS token\n",
    "        if torch.allclose(next_token_first.squeeze(), eos_token.to(device), atol=1e-1):\n",
    "            break\n",
    "\n",
    "        # Append the next token to the input sequence for further decoding\n",
    "        decoder_input_first = torch.cat([decoder_input_first, next_token_first], dim=1)\n",
    "\n",
    "    # Second decoding loop\n",
    "    while decoder_input_second.size(1) < max_len // 2:\n",
    "        # Build causal mask for decoder 2\n",
    "        decoder_mask_second = causal_mask(decoder_input_second.size(1)).type_as(decoder_input_second).to(device)\n",
    "\n",
    "        # Decode using the second decoder with its specific positional encoding\n",
    "        decoder_output_second = model.decode(\n",
    "            model.decoder_second,\n",
    "            encoder_output,\n",
    "            None,\n",
    "            decoder_input_second,\n",
    "            decoder_mask_second,\n",
    "            model.decoder_positional_encoding_second  # Pass the second positional encoding\n",
    "        )\n",
    "        proj_output_second = model.projection_second(model.projection_norm_second(decoder_output_second))\n",
    "\n",
    "        # Get the next predicted token\n",
    "        next_token_second = proj_output_second[:, -1].unsqueeze(0)\n",
    "\n",
    "        # Append to the decoded sequence\n",
    "        decoded_second.append(next_token_second.squeeze(0).detach().cpu())\n",
    "\n",
    "        # Check for the EOS token\n",
    "        if torch.allclose(next_token_second.squeeze(), eos_token.to(device), atol=1e-1):\n",
    "            break\n",
    "\n",
    "        # Append the next token to the input sequence for further decoding\n",
    "        decoder_input_second = torch.cat([decoder_input_second, next_token_second], dim=1)\n",
    "\n",
    "    return decoder_input_first.squeeze(0), decoder_input_second.squeeze(0), curve_emb, adj_emb\n",
    "\n",
    "\n",
    "def causal_mask(size):\n",
    "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
    "    return mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    results_dir = '1024_dim_h_32_results_clip_bs_512'\n",
    "    max_mech_size = 10\n",
    "    num_conditions = 200  # Number of different adjacency conditions to test per curve\n",
    "    prefix_rows = np.array([[0.5, 0.5], [0.6, 0.5]], dtype=np.float32)\n",
    "    plt_style = {\n",
    "        'truth_joints': {'color': 'red', 'marker': 'o', 's': 60, 'label': 'Truth Joints'},\n",
    "        'pred_joints': {'color': 'blue', 'marker': 'x', 's': 60, 'label': 'Pred Joints'},\n",
    "        'truth_curve': {'color': 'magenta', 'linestyle': '-', 'linewidth': 3, 'label': 'Truth Curve'},\n",
    "        'pred_curve': {'color': 'cyan', 'linestyle': '-', 'linewidth': 2, 'label': 'Predicted Curve'},\n",
    "        'cond_curve': {'color': 'green', 'linestyle': '--', 'linewidth': 2, 'label': 'Condition Curve'}\n",
    "    }\n",
    "\n",
    "# Invalid joint values to remove\n",
    "INVALID_JOINTS = np.array([\n",
    "    [-1.0, -1.0],\n",
    "    [1.0,  1.0],\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device).float()  # assume `model` is already defined elsewhere\n",
    "\n",
    "@contextmanager\n",
    "def managed_figure(figsize=(10, 8)):\n",
    "    \"\"\"Context manager to ensure figures are properly cleaned up\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    try:\n",
    "        yield ax\n",
    "    finally:\n",
    "        plt.close(fig)\n",
    "\n",
    "def prepare_results_dir():\n",
    "    \"\"\"Prepare clean results directory\"\"\"\n",
    "    if os.path.exists(Config.results_dir):\n",
    "        shutil.rmtree(Config.results_dir)\n",
    "    os.makedirs(Config.results_dir, exist_ok=True)\n",
    "\n",
    "def process_adjacency(adj_tensor):\n",
    "    \"\"\"Convert raw adjacency to simulation format\"\"\"\n",
    "    adj = adj_tensor.detach().cpu().squeeze().float().numpy()\n",
    "    valid_mask = ~np.all(adj == 0, axis=1)\n",
    "    adj = adj[valid_mask][:, valid_mask]\n",
    "    node_types = np.diag(adj).astype(bool)\n",
    "    np.fill_diagonal(adj, 0)\n",
    "    return adj.astype(np.float32), node_types\n",
    "\n",
    "def simulate(adj, joints, node_types):\n",
    "    \"\"\"Run simulation with error handling\"\"\"\n",
    "    try:\n",
    "        if adj.dtype != np.float32:\n",
    "            adj = adj.astype(np.float32)\n",
    "        if joints.dtype != np.float32:\n",
    "            joints = joints.astype(np.float32)\n",
    "        \n",
    "        result = simulate_mechanism(adj, joints, node_types)\n",
    "        if result is None:\n",
    "            return None\n",
    "        \n",
    "        trajectory = torch.tensor(result[-1], dtype=torch.float32).unsqueeze(0)\n",
    "        return preprocess_curves(trajectory).detach().cpu().numpy().squeeze()\n",
    "    except Exception as e:\n",
    "        print(f\"Simulation failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_joints(pred_first, pred_second):\n",
    "    \"\"\"Combine and prepare joint positions\"\"\"\n",
    "    joints = torch.cat([\n",
    "        pred_first[1:].detach().cpu().float(),\n",
    "        pred_second[1:].detach().cpu().float()\n",
    "    ], dim=0)\n",
    "    return np.concatenate([Config.prefix_rows, joints.numpy()], axis=0)\n",
    "\n",
    "def save_plot(ax, curve_dir, filename, title=None):\n",
    "    \"\"\"Helper function to save plots with guaranteed cleanup\"\"\"\n",
    "    try:\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(curve_dir, filename))\n",
    "    finally:\n",
    "        plt.close()\n",
    "\n",
    "def filter_invalid_joints(joints: np.ndarray, invalid_values: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Remove any row in `joints` that exactly matches any row in `invalid_values`.\"\"\"\n",
    "    mask = np.ones(len(joints), dtype=bool)\n",
    "    for invalid in invalid_values:\n",
    "        mask &= ~np.all(joints == invalid, axis=1)\n",
    "    return joints[mask]\n",
    "\n",
    "def create_curve_plot(ax, truth_joints, pred_joints, gt_curve=None, pred_curve=None, \n",
    "                     cond_curve=None, title=None):\n",
    "    \"\"\"Create a standardized plot with proper error handling\"\"\"\n",
    "    try:\n",
    "        if gt_curve is not None:\n",
    "            ax.plot(gt_curve[:, 0], gt_curve[:, 1], **Config.plt_style['truth_curve'])\n",
    "        if pred_curve is not None:\n",
    "            ax.plot(pred_curve[:, 0], pred_curve[:, 1], **Config.plt_style['pred_curve'])\n",
    "        if cond_curve is not None:\n",
    "            ax.plot(cond_curve[:, 0], cond_curve[:, 1], **Config.plt_style['cond_curve'])\n",
    "        \n",
    "        ax.scatter(truth_joints[:, 0], truth_joints[:, 1], **Config.plt_style['truth_joints'])\n",
    "        ax.scatter(pred_joints[:, 0], pred_joints[:, 1], **Config.plt_style['pred_joints'])\n",
    "        \n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "    except Exception as e:\n",
    "        print(f\"Plotting error: {str(e)}\")\n",
    "\n",
    "# Main processing\n",
    "prepare_results_dir()\n",
    "\n",
    "for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "    if batch_idx == 100:\n",
    "        break\n",
    "\n",
    "    # Create subfolder for this curve\n",
    "    curve_dir = os.path.join(Config.results_dir, f'curve_{batch_idx}')\n",
    "    os.makedirs(curve_dir, exist_ok=True)\n",
    "    \n",
    "    # Prepare data\n",
    "    curve_data = batch[\"curve_numerical\"].to(device).float()\n",
    "    gt_adj = batch[\"adjacency\"].to(device).float()\n",
    "    \n",
    "    # Get ground truth joints\n",
    "    truth_joints = torch.cat([\n",
    "        batch[\"label_first\"].view(-1, 2)[:-1].detach().cpu().float(),\n",
    "        batch[\"label_second\"].view(-1, 2)[:-1].detach().cpu().float()\n",
    "    ], dim=0)\n",
    "    truth_joints = np.concatenate([Config.prefix_rows, truth_joints.numpy()], axis=0)\n",
    "    \n",
    "    # Process ground truth adjacency\n",
    "    gt_adj_processed, gt_node_types = process_adjacency(gt_adj)\n",
    "    \n",
    "    # Get prediction with ground truth adjacency\n",
    "    with torch.no_grad():\n",
    "        pred_first, pred_second, curve_emb, adj_emb = greedy_decode_conditional(\n",
    "            model, curve_data, gt_adj, Config.max_mech_size\n",
    "        )\n",
    "    pred_joints = get_joints(pred_first, pred_second)\n",
    "\n",
    "    # Filter out invalid joints\n",
    "    pred_joints = filter_invalid_joints(pred_joints, INVALID_JOINTS)\n",
    "    truth_joints = filter_invalid_joints(truth_joints, INVALID_JOINTS)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cos_sim = F.cosine_similarity(curve_emb, adj_emb, dim=-1)\n",
    "    sim_val = cos_sim.mean().item()\n",
    "\n",
    "    # Run simulations\n",
    "    gt_curve = simulate(gt_adj_processed, truth_joints, gt_node_types)\n",
    "    pred_curve = simulate(gt_adj_processed, pred_joints, gt_node_types)\n",
    "    \n",
    "    # Plot 1: Ground Truth vs Prediction with GT Adjacency\n",
    "    with managed_figure() as ax:\n",
    "        create_curve_plot(\n",
    "            ax, truth_joints, pred_joints,\n",
    "            gt_curve=gt_curve, pred_curve=pred_curve,\n",
    "            title=f'Curve {batch_idx}: GT vs Pred (sim={sim_val:.4f})'\n",
    "        )\n",
    "        save_plot(ax, curve_dir, f'gt_vs_pred_sim_{sim_val:.4f}.png')\n",
    "    \n",
    "    # Plot each condition separately\n",
    "    for cond_idx in range(Config.num_conditions):\n",
    "        cond_adj = dataset[(batch_idx + cond_idx) % len(dataset)][\"adjacency\"].to(device).float()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            cond_first, cond_second, cond_curve_emb, cond_adj_emb = greedy_decode_conditional(\n",
    "                model, curve_data, cond_adj.unsqueeze(0), Config.max_mech_size\n",
    "            )\n",
    "        cond_joints = get_joints(cond_first, cond_second)\n",
    "        cond_joints = filter_invalid_joints(cond_joints, INVALID_JOINTS)\n",
    "        cond_adj_processed, cond_node_types = process_adjacency(cond_adj)\n",
    "        cond_curve = simulate(cond_adj_processed, cond_joints, cond_node_types)\n",
    "        \n",
    "        # Skip this condition if cond_curve is not generated\n",
    "        if cond_curve is None:\n",
    "            plt.close()  # Ensure any existing figure is closed\n",
    "            continue  # Skip to next condition\n",
    "            \n",
    "        # Compute cosine similarity for this condition\n",
    "        cond_cos_sim = F.cosine_similarity(cond_curve_emb, cond_adj_emb, dim=-1)\n",
    "        cond_sim_val = cond_cos_sim.mean().item()\n",
    "\n",
    "        with managed_figure() as ax:\n",
    "            create_curve_plot(\n",
    "                ax, truth_joints, cond_joints,\n",
    "                gt_curve=gt_curve, cond_curve=cond_curve,\n",
    "                title=f'Curve {batch_idx} Cond {cond_idx} (sim={cond_sim_val:.4f})'\n",
    "            )\n",
    "            save_plot(ax, curve_dir, f'condition_{cond_idx}_sim_{cond_sim_val:.4f}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
